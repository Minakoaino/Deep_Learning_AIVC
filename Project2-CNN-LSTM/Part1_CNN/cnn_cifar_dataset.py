# -*- coding: utf-8 -*-
#Made by Asimina Tzana 
#AIVC21015
#aivc21015@uniwa.gr
"""cnn_cifar_dataset.ipynb



Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YLP9rg8rWM2FgkRyxi3CR8Fpe54VPj-i

### Cifar 10 dataset CNN

![image.png](attachment:image.png)
"""

# Commented out IPython magic to ensure Python compatibility.
# import the libraries
import os
import os.path
from os import path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.regularizers import l2
from sklearn.model_selection import train_test_split

from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import accuracy_score
import itertools

# %matplotlib inline

def load_CIFAR_batch(filename):
    with open(filename,"rb") as f:
        data_dict = np.load(f,encoding="bytes", allow_pickle=True)
        images = data_dict[b"data"]
        labels = data_dict[b"labels"]
        images = images.reshape(10000,3,32,32)
        images = images.transpose(0,2,3,1)
        labels = np.array(labels)
        return images,labels

def load_CIFAR_data(data_dir):
    images_train=[]
    labels_train=[]
    for i in range(1):
        f = os.path.join(data_dir,"data_batch_1")
        print(" Being loaded ",f)
        image_batch,label_batch = load_CIFAR_batch(f)
        images_train.append(image_batch)
        labels_train.append(label_batch)
        X_train = np.concatenate(images_train)
        Y_train = np.concatenate(labels_train)
        del image_batch,label_batch
    X_test,Y_test = load_CIFAR_batch(os.path.join(data_dir,"test_batch"))    
    return X_train,Y_train,X_test,Y_test
print(" Import complete ")

#from google.colab import drive
#drive.mount('/content/drive')


data_dir = r"inputData\cifar-10-batches-py"
X_train,Y_train,X_test,Y_test = load_CIFAR_data(data_dir)

# # Concatenate train and test images
X = np.concatenate((X_train,X_test))
y = np.concatenate((Y_train,Y_test))

# Split data
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, random_state=1234)

print("The training data shape is:\t",X_train.shape)
print("The training labels shape:\t",Y_train.shape)
print("The test data shape is:\t",X_test.shape)
print("The test labels shape is:\t",Y_test.shape)

"""### Plot some random images"""

plt.title('Some random image')
plt.imshow(X_train[9]);

for i in range(0,10):
    fig = plt.gcf()
    fig.set_size_inches(12,6)
    ax = plt.subplot(2,5,i+1)
    #  Remove the axis 
    plt.xticks([])
    plt.yticks([])

    #  Remove the black box 
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.spines['left'].set_visible(False)
    #  Set the spacing between subgraphs 
    plt.subplots_adjust(left=0.10, top=0.88, right=0.65, bottom=0.08, wspace=0.02, hspace=0.02)
    ax.imshow(X_train[i],cmap="binary")

batch_size = 32  # The default batch size of keras.
num_classes = 10  # Number of class for the dataset
epochs = 100
data_augmentation = False

"""### Read some images with their classes"""

# plotting some random 10 images

class_names = ['airplane','automobile','bird','cat','deer',
               'dog','frog','horse','ship','truck']

fig = plt.figure(figsize=(10,5))
for i in range(num_classes):
    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])
    idx = np.where(Y_train[:]==i)[0]
    features_idx = X_train[idx,::]
    img_num = np.random.randint(features_idx.shape[0])
    im = (features_idx[img_num,::])
    ax.set_title(class_names[i])
    plt.imshow(im)
plt.show()

fig = plt.figure(figsize=(10,5))
for i in range(num_classes):
    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])
    idx = np.where(Y_train[:]==i)[0]
    features_idx = X_train[idx,::]
    img_num = np.random.randint(features_idx.shape[0])
    im = (features_idx[img_num,::])
    ax.set_title(class_names[i])
    plt.imshow(im)
    plt.suptitle("Actual classes of CIFAR-10 Data", size=30, color="#6166B3")

plt.show()

fig = plt.figure(figsize=(10,5))
for i in range(num_classes):
    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])
    idx = np.where(Y_train[:]==i)[0]
    features_idx = X_train[idx,::]
    img_num = np.random.randint(features_idx.shape[0])
    im = (features_idx[img_num,::])
    ax.set_title(class_names[i])
    plt.imshow(im)
plt.show()

"""### Normalizing the training data

"""

# # Normalize the data. Before we need to connvert data type to float for computation.
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255

# Convert class vectors to binary class matrices. This is called one hot encoding.
Y_train = keras.utils.np_utils.to_categorical(Y_train, num_classes)
Y_test = keras.utils.np_utils.to_categorical(Y_test, num_classes)

# Building the CNN Model (Hidden Output)

model = Sequential()
# CONV => RELU => CONV => RELU => POOL => DROPOUT
model.add(Conv2D(64, (3, 3), padding='same',
                 input_shape=X_train.shape[1:]))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# CONV => RELU => CONV => RELU => POOL => DROPOUT
model.add(Conv2D(128, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(Conv2D(128, (3, 3)))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# FLATTERN => DENSE => RELU => DROPOUT
model.add(Flatten())
model.add(Dense(512,kernel_regularizer=l2(0.01)))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes))
model.add(Activation('softmax'))
model.summary()

#!pip install visualkeras

# Visualizing our model (Hidden Input)
#visualkeras.layered_view(model, scale_xy=10, legend=True)

# Let's train the model
model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])

# Save model training in a variable called history in order to plot it later.
history = model.fit(X_train, Y_train,
          batch_size=batch_size,
          epochs=epochs,
          validation_data=(X_test, Y_test),
          shuffle=True)

import os.path
from os import path

#create directory to store the model
#!mkdir drive/MyDrive/aivc21015_project2/OutputData
#store model in outputdata folder
#print("Saving as Model.h5")
#model.save("drive/MyDrive/aivc21015_project2/OutputData/Model.h5")

# Plotting the Model Accuracy & Model Loss vs Epochs (Hidden Input)
plt.figure(figsize=[20,8])

# summarize history for accuracy
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy', size=25, pad=20)
plt.ylabel('Accuracy', size=15)
plt.xlabel('Epoch', size=15)
plt.legend(['train', 'test'], loc='upper left')
# summarize history for loss

plt.subplot(1,2,2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss', size=25, pad=20)
plt.ylabel('Loss', size=15)
plt.xlabel('Epoch', size=15)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']
pred = model.predict(X_test)
# Convert predictions classes to one hot vectors 
Y_pred_classes = np.argmax(pred, axis=1) 
# Convert validation observations to one hot vectors
Y_true = np.argmax(Y_test, axis=1)
# Errors are difference between predicted labels and true labels
errors = (Y_pred_classes - Y_true != 0)

# Score trained model.
scores = model.evaluate(X_train, Y_train, verbose=1)
print('Test loss:', scores[0])
print('Accuracy on train data:', scores[1])

# make prediction.
pred = model.predict(X_train)

# Score trained model.
scores = model.evaluate(X_test, Y_test, verbose=1)
print('Test loss:', scores[0])
print('Test accuracy:', scores[1])

# make prediction.
pred = model.predict(X_test)

print(classification_report(Y_true, Y_pred_classes))

# Creates a confusion matrix
cm = confusion_matrix(Y_true, Y_pred_classes)
cm_df = pd.DataFrame(cm,
                     index = labels, 
                     columns = labels)

#Plots the confusion matrix
plt.figure(figsize=(15,10))
sns.heatmap(cm_df, annot=True, fmt=".1f")
plt.title('Support Vector Classification \nAccuracy:{0:.3f}'.format(accuracy_score(Y_true, Y_pred_classes)))
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

"""### Make predictions"""

# Checking the predictions! (Hidden Input)
predictions = model.predict(X_test)

plt.figure(figsize=[10,10])

class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']

plt.subplot(2,2,1)
n = 3
plt.imshow(X_test[n].reshape(32, 32, -1), cmap=plt.cm.binary)
plt.title("Predicted value: " + str(class_names[np.argmax(pred[n], axis=0)]), size=20)
plt.grid(False)

plt.subplot(2,2,2)
n = 4
plt.imshow(X_test[n].reshape(32, 32, -1), cmap=plt.cm.binary)
plt.title("Predicted value: " + str(class_names[np.argmax(pred[n], axis=0)]), size=20)
plt.grid(False)

plt.subplot(2,2,3)
n = 8
plt.imshow(X_test[n].reshape(32, 32, -1), cmap=plt.cm.binary)
plt.title("Predicted value: " + str(class_names[np.argmax(pred[n], axis=0)]), size=20)
plt.grid(False)

plt.subplot(2,2,4)
n = 6
plt.imshow(X_test[n].reshape(32, 32, -1), cmap=plt.cm.binary)
plt.title("Predicted value: " + str(class_names[np.argmax(pred[n], axis=0)]), size=20)
plt.grid(False)


plt.suptitle("Predictions of CIFAR-10 Data", size=30, color="#6166B3")

plt.show()